{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "args = {\n",
        "    'model_path': 'meta-llama/Meta-Llama-3.1-8B-Instruct',\n",
        "    'task': 'text-generation',\n",
        "    'torch_dtype': torch.bfloat16,\n",
        "    'device_map': 'auto',\n",
        "    'do_sample': True,\n",
        "    'temperature': 0.1,\n",
        "    'max_new_tokens': 700,\n",
        "    'num_gpus': 1,\n",
        "    'load_8bit': False,\n",
        "    'cpu_offloading': False,\n",
        "    'max_gpu_memory': None,\n",
        "    'revision': 'main',\n",
        "    'debug': False,\n",
        "    'top_p': 1,\n",
        "    'full_texts_dir': '/content/drive/MyDrive/AI/MultiClinSum 2025/Data/fulltext',\n",
        "    'output_dir': '/content/drive/MyDrive/AI/MultiClinSum 2025/Results/Baseline'\n",
        "}\n",
        "\n",
        "class DotDict:\n",
        "    def __init__(self, dictionary):\n",
        "        self._data = dictionary\n",
        "\n",
        "    def __getattr__(self, key):\n",
        "        if key in self._data:\n",
        "            return self._data[key]\n",
        "        else:\n",
        "            raise AttributeError(f\"'DotDict' object has no attribute '{key}'\")\n",
        "\n",
        "    def __setattr__(self, key, value):\n",
        "        if key == '_data':\n",
        "            super().__setattr__(key, value)\n",
        "        else:\n",
        "            self._data[key] = value\n",
        "\n",
        "    def __delattr__(self, key):\n",
        "        if key in self._data:\n",
        "            del self._data[key]\n",
        "        else:\n",
        "            raise AttributeError(f\"'DotDict' object has no attribute '{key}'\")\n",
        "\n",
        "args = DotDict(args)"
      ],
      "metadata": {
        "id": "Nif2oWvqyvrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "summarization_pipeline = pipeline(\n",
        "    args.task,\n",
        "    model=args.model_path,\n",
        "    model_kwargs={\"torch_dtype\": args.torch_dtype},\n",
        "    device_map=args.device_map,\n",
        "    max_new_tokens=args.max_new_tokens,\n",
        "    do_sample=args.do_sample,\n",
        "    temperature=args.temperature,\n",
        "    top_p=args.top_p\n",
        ")"
      ],
      "metadata": {
        "id": "fAsxbrlny8G-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_summary(text_to_summarize):\n",
        "  messages = [\n",
        "  {\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"Eres un asistente médico experto en redactar resúmenes clínicos concisos y precisos en español. Tu tarea es analizar informes de casos clínicos y generar un resumen narrativo que destaque los aspectos más relevantes para profesionales de la salud, incluyendo hallazgos médicos clave como resultados de pruebas importantes y otras observaciones significativas. El resumen debe presentarse en un solo párrafo, sin utilizar viñetas, encabezados ni ningún tipo de formato especial.\"\n",
        "  },\n",
        "  {\n",
        "    \"role\": \"user\",\n",
        "    \"content\": f\"Por favor, resume el siguiente informe de caso clínico en español, enfocándote en:\\n\\n- Datos clínicos clave\\n- Resultados de pruebas importantes (laboratorio, imagenología, etc.)\\n- Diagnóstico\\n- Tratamiento\\n- Evolución del paciente\\n\\nAsegúrate de que el resumen sea claro, coherente y útil para profesionales médicos. Presenta el resumen en un solo párrafo, sin utilizar viñetas, encabezados ni ningún tipo de formato especial.\\n\\n{text_to_summarize}\"\n",
        "  }\n",
        " ]\n",
        "\n",
        "  return summarization_pipeline(messages)[0][\"generated_text\"][-1][\"content\"]"
      ],
      "metadata": {
        "id": "iHaeKAxl0Ipb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "done = list(os.listdir(args.output_dir))\n",
        "\n",
        "full_text_file_names_sorted = sorted(\n",
        "    [f for f in os.listdir(args.full_texts_dir) if f.endswith(\".txt\")],\n",
        "    key=lambda x: int(x.split('_')[-1].removesuffix('.txt'))\n",
        ")\n",
        "\n",
        "for file_name in full_text_file_names_sorted:\n",
        "  if file_name in done:\n",
        "    print(\"Skipping\", file_name)\n",
        "    continue\n",
        "\n",
        "  print(\"Summarizing\", file_name)\n",
        "  with open(f\"{args.full_texts_dir}/{file_name}\", \"r\") as in_file:\n",
        "    with open(f\"{args.output_dir}/{file_name}\", \"w\") as out_file:\n",
        "      out_file.write(get_summary(in_file.read()))"
      ],
      "metadata": {
        "id": "MvakHp49aqHn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}